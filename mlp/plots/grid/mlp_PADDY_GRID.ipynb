{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paddy - GRID PARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.388066   \n",
      "1      2          2  0.460553   \n",
      "2      3          3  0.473766   \n",
      "3      4          4  0.502600   \n",
      "4      5          5  0.536443   \n",
      "\n",
      "                                            Filename  \n",
      "0  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...  \n",
      "1  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...  \n",
      "2  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...  \n",
      "3  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...  \n",
      "4  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...  \n",
      "\n",
      "DataFrame with Qmax and YT:\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.388066   \n",
      "1      2          2  0.460553   \n",
      "2      3          3  0.473766   \n",
      "3      4          4  0.502600   \n",
      "4      5          5  0.536443   \n",
      "\n",
      "                                            Filename  Qmax  YT  \n",
      "0  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
      "1  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
      "2  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
      "3  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
      "4  MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Qmax</th>\n",
       "      <th>YT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.388066</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.460553</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473766</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.536443</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>156</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528634</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>0.582096</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>159</td>\n",
       "      <td>7</td>\n",
       "      <td>0.581697</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>0.579492</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count  Iteration   Fitness  \\\n",
       "0         1          1  0.388066   \n",
       "1         2          2  0.460553   \n",
       "2         3          3  0.473766   \n",
       "3         4          4  0.502600   \n",
       "4         5          5  0.536443   \n",
       "...     ...        ...       ...   \n",
       "3009    156          4  0.528634   \n",
       "3010    157          5  0.582096   \n",
       "3011    158          6  0.577689   \n",
       "3012    159          7  0.581697   \n",
       "3013    160          8  0.579492   \n",
       "\n",
       "                                               Filename  Qmax  YT  \n",
       "0     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "1     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "2     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "3     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "4     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "...                                                 ...   ...  ..  \n",
       "3009  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3010  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3011  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3012  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3013  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "\n",
       "[3014 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re  # Import regular expressions module\n",
    "\n",
    "# Define the directory containing the log files\n",
    "log_dir = 'data/GD/'\n",
    "\n",
    "# Use glob to find all .log files in the directory\n",
    "log_files = glob.glob(os.path.join(log_dir, '*.log'))\n",
    "\n",
    "# Initialize an empty list to store data from all log files\n",
    "all_data = []\n",
    "\n",
    "# Function to extract Qmax and YT from the filename\n",
    "def extract_qmax_yt(filename):\n",
    "    \"\"\"\n",
    "    Extracts Qmax and YT values from a given filename.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The name of the file.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing Qmax and YT as integers. Returns (None, None) if not found.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to capture Qmax and YT values\n",
    "    pattern = re.compile(r'Qmax(\\d+)_YT(\\d+)', re.IGNORECASE)\n",
    "    match = pattern.search(filename)\n",
    "    \n",
    "    if match:\n",
    "        qmax = int(match.group(1))\n",
    "        yt = int(match.group(2))\n",
    "        return qmax, yt\n",
    "    else:\n",
    "        # If pattern not found, return None\n",
    "        return None, None\n",
    "\n",
    "# Iterate through each log file\n",
    "for log_file_path in log_files:\n",
    "    fitness_scores = []\n",
    "    filename = os.path.basename(log_file_path)  # Extract the filename\n",
    "    \n",
    "    try:\n",
    "        with open(log_file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Iterate through the lines using index to allow lookahead\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"Top seed in generation:\" in line:\n",
    "                # Ensure there is a next line to read\n",
    "                if i + 1 < len(lines):\n",
    "                    next_line = lines[i + 1].strip()\n",
    "                    if \"fitness:\" in next_line:\n",
    "                        try:\n",
    "                            # Extract fitness score\n",
    "                            fitness = float(next_line.split(\"fitness:\")[1].split()[0])\n",
    "                            fitness_scores.append(fitness)\n",
    "                        except (IndexError, ValueError) as e:\n",
    "                            print(f\"Error parsing fitness in file {filename} on line {i+2}: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {log_file_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {filename}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate Count and Iteration columns\n",
    "    count = list(range(1, len(fitness_scores) + 1))\n",
    "    iterations = [(i % 8) + 1 for i in range(len(fitness_scores))]\n",
    "    \n",
    "    # Create a temporary DataFrame for the current log file\n",
    "    temp_df = pd.DataFrame({\n",
    "        'Count': count,\n",
    "        'Iteration': iterations,\n",
    "        'Fitness': fitness_scores,\n",
    "        'Filename': filename\n",
    "    })\n",
    "    \n",
    "    # Append the temporary DataFrame to the all_data list\n",
    "    all_data.append(temp_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "if all_data:\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    # Display the DataFrame\n",
    "    print(\"Combined DataFrame:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No data found in the log files.\")\n",
    "    df = pd.DataFrame()  # Create an empty DataFrame to avoid errors later\n",
    "\n",
    "# --- Extract Qmax and YT from Filename ---\n",
    "if not df.empty:\n",
    "    # Apply the extraction function to the 'Filename' column\n",
    "    df[['Qmax', 'YT']] = df['Filename'].apply(lambda x: pd.Series(extract_qmax_yt(x)))\n",
    "    \n",
    "    # Display the updated DataFrame with Qmax and YT\n",
    "    print(\"\\nDataFrame with Qmax and YT:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No data to process for Qmax and YT extraction.\")\n",
    "\n",
    "# Optional: Save the DataFrame to a CSV file\n",
    "# df.to_csv('combined_fitness_scores_with_qmax_yt.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making into 1 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed directory: data/GD/15dec/\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.389668   \n",
      "1      2          2  0.456946   \n",
      "2      3          3  0.506807   \n",
      "3      4          4  0.512211   \n",
      "4      5          5  0.556667   \n",
      "\n",
      "                                            Filename  Qmax  YT  \n",
      "0  MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
      "1  MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
      "2  MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
      "3  MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
      "4  MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
      "\n",
      "Processed directory: data/GS/\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.388066   \n",
      "1      2          2  0.477369   \n",
      "2      3          3  0.511213   \n",
      "3      4          4  0.525827   \n",
      "4      5          5  0.576090   \n",
      "\n",
      "                                            Filename  Qmax  YT  \n",
      "0  MLP_PADDY_Qmax20_YT4_20241213230635_Generation...    20   4  \n",
      "1  MLP_PADDY_Qmax20_YT4_20241213230635_Generation...    20   4  \n",
      "2  MLP_PADDY_Qmax20_YT4_20241213230635_Generation...    20   4  \n",
      "3  MLP_PADDY_Qmax20_YT4_20241213230635_Generation...    20   4  \n",
      "4  MLP_PADDY_Qmax20_YT4_20241213230635_Generation...    20   4  \n",
      "\n",
      "Processed directory: data/PD/15dec/\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.387265   \n",
      "1      2          2  0.459553   \n",
      "2      3          3  0.513815   \n",
      "3      4          4  0.516821   \n",
      "4      5          5  0.569283   \n",
      "\n",
      "                                            Filename  Qmax  YT  \n",
      "0  MLP_PADDY_Qmax25_YT5_20241215222112_Population...    25   5  \n",
      "1  MLP_PADDY_Qmax25_YT5_20241215222112_Population...    25   5  \n",
      "2  MLP_PADDY_Qmax25_YT5_20241215222112_Population...    25   5  \n",
      "3  MLP_PADDY_Qmax25_YT5_20241215222112_Population...    25   5  \n",
      "4  MLP_PADDY_Qmax25_YT5_20241215222112_Population...    25   5  \n",
      "\n",
      "Processed directory: data/PS/\n",
      "   Count  Iteration   Fitness  \\\n",
      "0      1          1  0.386264   \n",
      "1      2          2  0.502805   \n",
      "2      3          3  0.537844   \n",
      "3      4          4  0.566077   \n",
      "4      5          5  0.574488   \n",
      "\n",
      "                                            Filename  Qmax  YT  \n",
      "0  MLP_PADDY_Qmax30_YT6_20241213230934_Population...    30   6  \n",
      "1  MLP_PADDY_Qmax30_YT6_20241213230934_Population...    30   6  \n",
      "2  MLP_PADDY_Qmax30_YT6_20241213230934_Population...    30   6  \n",
      "3  MLP_PADDY_Qmax30_YT6_20241213230934_Population...    30   6  \n",
      "4  MLP_PADDY_Qmax30_YT6_20241213230934_Population...    30   6  \n",
      "\n",
      "Summary of DataFrames:\n",
      "df_GD: 1399 records\n",
      "df_GS: 1373 records\n",
      "df_PD: 1341 records\n",
      "df_PS: 1400 records\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Function to extract Qmax and YT from the filename\n",
    "def extract_qmax_yt(filename):\n",
    "    \"\"\"\n",
    "    Extracts Qmax and YT values from a given filename.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The name of the file.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing Qmax and YT as integers. Returns (None, None) if not found.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to capture Qmax and YT values\n",
    "    pattern = re.compile(r'Qmax(\\d+)_YT(\\d+)', re.IGNORECASE)\n",
    "    match = pattern.search(filename)\n",
    "    \n",
    "    if match:\n",
    "        qmax = int(match.group(1))\n",
    "        yt = int(match.group(2))\n",
    "        return qmax, yt\n",
    "    else:\n",
    "        # If pattern not found, return None\n",
    "        return None, None\n",
    "\n",
    "# Function to process a single log directory and return a DataFrame\n",
    "def process_log_dir(log_dir):\n",
    "    \"\"\"\n",
    "    Processes all .log files in the specified directory and extracts relevant data into a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        log_dir (str): The directory containing the log files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the combined data from all log files in the directory.\n",
    "    \"\"\"\n",
    "    # Use glob to find all .log files in the directory\n",
    "    log_files = glob.glob(os.path.join(log_dir, '*.log'))\n",
    "    \n",
    "    # Initialize an empty list to store data from all log files\n",
    "    all_data = []\n",
    "    \n",
    "    # Iterate through each log file\n",
    "    for log_file_path in log_files:\n",
    "        fitness_scores = []\n",
    "        filename = os.path.basename(log_file_path)  # Extract the filename\n",
    "        \n",
    "        try:\n",
    "            with open(log_file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            \n",
    "            # Iterate through the lines using index to allow lookahead\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"Top seed in generation:\" in line:\n",
    "                    # Ensure there is a next line to read\n",
    "                    if i + 1 < len(lines):\n",
    "                        next_line = lines[i + 1].strip()\n",
    "                        if \"fitness:\" in next_line:\n",
    "                            try:\n",
    "                                # Extract fitness score\n",
    "                                fitness = float(next_line.split(\"fitness:\")[1].split()[0])\n",
    "                                fitness_scores.append(fitness)\n",
    "                            except (IndexError, ValueError) as e:\n",
    "                                print(f\"Error parsing fitness in file {filename} on line {i+2}: {e}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {log_file_path}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {filename}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate Count and Iteration columns\n",
    "        count = list(range(1, len(fitness_scores) + 1))\n",
    "        iterations = [(i % 8) + 1 for i in range(len(fitness_scores))]\n",
    "        \n",
    "        # Create a temporary DataFrame for the current log file\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Count': count,\n",
    "            'Iteration': iterations,\n",
    "            'Fitness': fitness_scores,\n",
    "            'Filename': filename\n",
    "        })\n",
    "        \n",
    "        # Append the temporary DataFrame to the all_data list\n",
    "        all_data.append(temp_df)\n",
    "    \n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    if all_data:\n",
    "        df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Apply the extraction function to the 'Filename' column\n",
    "        df[['Qmax', 'YT']] = df['Filename'].apply(lambda x: pd.Series(extract_qmax_yt(x)))\n",
    "        \n",
    "        print(f\"\\nProcessed directory: {log_dir}\")\n",
    "        print(df.head())  # Display the first few rows of the DataFrame\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"No data found in the log files within directory: {log_dir}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame to avoid errors later\n",
    "\n",
    "# List of directories to process\n",
    "directories = {\n",
    "    'GD': 'data/GD/15dec/',\n",
    "    'GS': 'data/GS/',\n",
    "    'PD': 'data/PD/15dec/',\n",
    "    'PS': 'data/PS/'\n",
    "}\n",
    "\n",
    "# Dictionary to hold the resulting DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate through each directory and process the log files\n",
    "for key, dir_path in directories.items():\n",
    "    df = process_log_dir(dir_path)\n",
    "    dataframes[key] = df\n",
    "    # Optionally, assign each DataFrame to a separate variable\n",
    "    globals()[f'df_{key}'] = df\n",
    "\n",
    "# Accessing the individual DataFrames\n",
    "df_GD = dataframes['GD']\n",
    "df_GS = dataframes['GS']\n",
    "df_PD = dataframes['PD']\n",
    "df_PS = dataframes['PS']\n",
    "\n",
    "# Optionally, display summaries of each DataFrame\n",
    "print(\"\\nSummary of DataFrames:\")\n",
    "print(f\"df_GD: {df_GD.shape[0]} records\")\n",
    "print(f\"df_GS: {df_GS.shape[0]} records\")\n",
    "print(f\"df_PD: {df_PD.shape[0]} records\")\n",
    "print(f\"df_PS: {df_PS.shape[0]} records\")\n",
    "\n",
    "# Optional: Save each DataFrame to separate CSV files\n",
    "# df_GD.to_csv('combined_fitness_scores_GD.csv', index=False)\n",
    "# df_GS.to_csv('combined_fitness_scores_GS.csv', index=False)\n",
    "# df_PD.to_csv('combined_fitness_scores_PD.csv', index=False)\n",
    "# df_PS.to_csv('combined_fitness_scores_PS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Qmax</th>\n",
       "      <th>YT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.389668</td>\n",
       "      <td>MLP_PADDY_Qmax20_YT4_20241215222449_Generation...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.456946</td>\n",
       "      <td>MLP_PADDY_Qmax20_YT4_20241215222449_Generation...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506807</td>\n",
       "      <td>MLP_PADDY_Qmax20_YT4_20241215222449_Generation...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.512211</td>\n",
       "      <td>MLP_PADDY_Qmax20_YT4_20241215222449_Generation...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>MLP_PADDY_Qmax20_YT4_20241215222449_Generation...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0.575689</td>\n",
       "      <td>MLP_PADDY_Qmax30_YT3_20241215222449_Generation...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.579293</td>\n",
       "      <td>MLP_PADDY_Qmax30_YT3_20241215222449_Generation...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>0.583297</td>\n",
       "      <td>MLP_PADDY_Qmax30_YT3_20241215222449_Generation...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.583294</td>\n",
       "      <td>MLP_PADDY_Qmax30_YT3_20241215222449_Generation...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>MLP_PADDY_Qmax30_YT3_20241215222449_Generation...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1399 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count  Iteration   Fitness  \\\n",
       "0         1          1  0.389668   \n",
       "1         2          2  0.456946   \n",
       "2         3          3  0.506807   \n",
       "3         4          4  0.512211   \n",
       "4         5          5  0.556667   \n",
       "...     ...        ...       ...   \n",
       "1394     35          3  0.575689   \n",
       "1395     36          4  0.579293   \n",
       "1396     37          5  0.583297   \n",
       "1397     38          6  0.583294   \n",
       "1398     39          7  0.579693   \n",
       "\n",
       "                                               Filename  Qmax  YT  \n",
       "0     MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
       "1     MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
       "2     MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
       "3     MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
       "4     MLP_PADDY_Qmax20_YT4_20241215222449_Generation...    20   4  \n",
       "...                                                 ...   ...  ..  \n",
       "1394  MLP_PADDY_Qmax30_YT3_20241215222449_Generation...    30   3  \n",
       "1395  MLP_PADDY_Qmax30_YT3_20241215222449_Generation...    30   3  \n",
       "1396  MLP_PADDY_Qmax30_YT3_20241215222449_Generation...    30   3  \n",
       "1397  MLP_PADDY_Qmax30_YT3_20241215222449_Generation...    30   3  \n",
       "1398  MLP_PADDY_Qmax30_YT3_20241215222449_Generation...    30   3  \n",
       "\n",
       "[1399 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transformed data to data/results/GRID_GD.csv\n",
      "Saved transformed data to data/results/GRID_GS.csv\n",
      "Saved transformed data to data/results/GRID_PD.csv\n",
      "Saved transformed data to data/results/GRID_PS.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def transform_and_save_df(df, label, output_dir='data/results/'):\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame to the desired format and saves it as a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to transform.\n",
    "        label (str): The label indicating the type (e.g., 'GD', 'GS').\n",
    "        output_dir (str): The directory where the CSV file will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"No data to transform and save for {label}.\")\n",
    "        return\n",
    "    \n",
    "    # Transform the DataFrame\n",
    "    df['Repeat'] = (df['Count'] - 1) // 8 + 1  # Calculate Repeat\n",
    "    df['Generation'] = df['Iteration']       # Rename Iteration to Generation\n",
    "    df.rename(columns={'Fitness': 'F1_Score'}, inplace=True)  # Rename Fitness to F1_Score\n",
    "    \n",
    "    # Keep only the required columns in the desired order\n",
    "    transformed_df = df[['Repeat', 'Generation', 'F1_Score', 'Filename', 'Qmax', 'YT']]\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(output_dir, f'GRID_{label}.csv')\n",
    "    \n",
    "    # Save the transformed DataFrame to CSV\n",
    "    transformed_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved transformed data to {output_file}\")\n",
    "    \n",
    "    # Optionally, return the transformed DataFrame\n",
    "    return transformed_df\n",
    "\n",
    "\n",
    "# Define the output directory for CSV files\n",
    "output_directory = 'data/results/'\n",
    "# Iterate through each DataFrame, transform, and save as CSV\n",
    "transformed_dataframes = {}\n",
    "for key, df in dataframes.items():\n",
    "    transformed_df = transform_and_save_df(df, key, output_dir=output_directory)\n",
    "    transformed_dataframes[key] = transformed_df\n",
    "\n",
    "# Optionally, assign transformed DataFrames to separate variables\n",
    "df_GD_transformed = transformed_dataframes.get('GD', pd.DataFrame())\n",
    "df_GS_transformed = transformed_dataframes.get('GS', pd.DataFrame())\n",
    "df_PD_transformed = transformed_dataframes.get('PD', pd.DataFrame())\n",
    "df_PS_transformed = transformed_dataframes.get('PS', pd.DataFrame())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final summary to data/results/SUMMARY_GD.csv\n",
      "Saved final summary to data/results/SUMMARY_GS.csv\n",
      "Saved final summary to data/results/SUMMARY_PD.csv\n",
      "Saved final summary to data/results/SUMMARY_PS.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_final_summary(df, label, output_dir='data/results/'):\n",
    "    \"\"\"\n",
    "    Creates a final summary DataFrame from the transformed DataFrame and saves it as a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The transformed DataFrame to summarize.\n",
    "        label (str): The label indicating the type (e.g., 'GD', 'GS', 'PD', 'PS') to be used in the output filename.\n",
    "        output_dir (str): The directory where the summary CSV file will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The final summary DataFrame.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"No data to summarize for {label}. Skipping summary creation.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # --- Group by 'Repeat' and 'Filename' to get the Best F1_Score ---\n",
    "    summary_df = df.groupby(['Repeat', 'Filename'], as_index=False).agg(\n",
    "        Best_F1_Score=('F1_Score', 'max'),\n",
    "        Qmax=('Qmax', 'first'),  # Assuming Qmax is constant per Filename\n",
    "        YT=('YT', 'first')       # Assuming YT is constant per Filename\n",
    "    )\n",
    "    \n",
    "    # --- Calculate Final Summary Statistics per Filename ---\n",
    "    final_summary_df = summary_df.groupby('Filename').agg(\n",
    "        Best_F1_Score=('Best_F1_Score', 'max'),\n",
    "        Worst_F1_Score=('Best_F1_Score', 'min'),\n",
    "        Avg_F1_Score=('Best_F1_Score', 'mean'),\n",
    "        StdDev_F1_Score=('Best_F1_Score', 'std'),\n",
    "        Qmax=('Qmax', 'first'),  # Since Qmax is constant per Filename\n",
    "        YT=('YT', 'first')       # Since YT is constant per Filename\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Optional: Round the statistics for better readability\n",
    "    final_summary_df['Avg_F1_Score'] = final_summary_df['Avg_F1_Score'].round(4)\n",
    "    final_summary_df['StdDev_F1_Score'] = final_summary_df['StdDev_F1_Score'].round(4)\n",
    "    \n",
    "    # Reorder columns to have Filename first, followed by Qmax and YT, then the statistics\n",
    "    final_summary_df = final_summary_df[['Filename', 'Qmax', 'YT', \n",
    "                                         'Best_F1_Score', 'Worst_F1_Score', \n",
    "                                         'Avg_F1_Score', 'StdDev_F1_Score']]\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(output_dir, f'SUMMARY_{label}.csv')\n",
    "    \n",
    "    # Save the final summary DataFrame to CSV\n",
    "    final_summary_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved final summary to {output_file}\")\n",
    "    \n",
    "    return final_summary_df\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Assume transformed_dataframes is a dictionary containing the transformed DataFrames\n",
    "# for each label ('GD', 'GS', 'PD', 'PS')\n",
    "# Example:\n",
    "# transformed_dataframes = {\n",
    "#     'GD': df_GD_transformed,\n",
    "#     'GS': df_GS_transformed,\n",
    "#     'PD': df_PD_transformed,\n",
    "#     'PS': df_PS_transformed\n",
    "# }\n",
    "\n",
    "# For demonstration, let's create dummy transformed DataFrames\n",
    "# You should replace this with your actual transformed DataFrames\n",
    "\n",
    "# Example Dummy DataFrames (Remove or replace these with actual data)\n",
    "# -----------------------------------------------------------------------------------\n",
    "# Uncomment and modify the following lines with your actual transformed DataFrames\n",
    "# df_GD_transformed = pd.read_csv('data/results/GRID_GD.csv')\n",
    "# df_GS_transformed = pd.read_csv('data/results/GRID_GS.csv')\n",
    "# df_PD_transformed = pd.read_csv('data/results/GRID_PD.csv')\n",
    "# df_PS_transformed = pd.read_csv('data/results/GRID_PS.csv')\n",
    "\n",
    "# For the purpose of this example, let's assume transformed_dataframes is already defined\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# List of labels and corresponding transformed DataFrames\n",
    "labels = ['GD', 'GS', 'PD', 'PS']\n",
    "transformed_dataframes = {\n",
    "    'GD': df_GD_transformed,\n",
    "    'GS': df_GS_transformed,\n",
    "    'PD': df_PD_transformed,\n",
    "    'PS': df_PS_transformed\n",
    "}\n",
    "\n",
    "# Iterate through each transformed DataFrame, create summary, and save as CSV\n",
    "for label in labels:\n",
    "    df = transformed_dataframes.get(label, pd.DataFrame())\n",
    "    summary = create_final_summary(df, label, output_dir='data/results/')\n",
    "    # Optionally, store the summaries in a dictionary if further processing is needed\n",
    "    # summaries[label] = summary\n",
    "\n",
    "# --- Optional: Accessing the Summaries ---\n",
    "# The summaries are saved as CSV files in 'data/results/' directory.\n",
    "# You can also access them programmatically if stored in a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Generation</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Qmax</th>\n",
       "      <th>YT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.388066</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.460553</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473766</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.536443</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT5_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528634</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.582096</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.581697</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.579492</td>\n",
       "      <td>MLP_PADDY_Qmax10_YT6_20241213230415_Generation...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repeat  Generation  F1_Score  \\\n",
       "0          1           1  0.388066   \n",
       "1          1           2  0.460553   \n",
       "2          1           3  0.473766   \n",
       "3          1           4  0.502600   \n",
       "4          1           5  0.536443   \n",
       "...      ...         ...       ...   \n",
       "3009      20           4  0.528634   \n",
       "3010      20           5  0.582096   \n",
       "3011      20           6  0.577689   \n",
       "3012      20           7  0.581697   \n",
       "3013      20           8  0.579492   \n",
       "\n",
       "                                               Filename  Qmax  YT  \n",
       "0     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "1     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "2     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "3     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "4     MLP_PADDY_Qmax10_YT5_20241213230415_Generation...    10   5  \n",
       "...                                                 ...   ...  ..  \n",
       "3009  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3010  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3011  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3012  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "3013  MLP_PADDY_Qmax10_YT6_20241213230415_Generation...    10   6  \n",
       "\n",
       "[3014 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the DataFrame to the desired format\n",
    "df['Repeat'] = (df['Count'] - 1) // 8 + 1  # Calculate Repeat\n",
    "df['Generation'] = df['Iteration']  # Rename Iteration to Generation\n",
    "df.rename(columns={'Fitness': 'F1_Score'}, inplace=True)  # Rename Fitness to F1_Score\n",
    "\n",
    "# Keep only the required columns in the desired order\n",
    "transformed_df = df[['Repeat', 'Generation', 'F1_Score', 'Filename','Qmax', 'YT']]\n",
    "transformed_df.to_csv('data/results/GRID_GD.csv', index=False)\n",
    "transformed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
