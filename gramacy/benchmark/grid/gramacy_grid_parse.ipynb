{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT30_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax500_YT25_20241215150318_QMAX500_YT25_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax1000_YT25_20241215150318_QMAX1000_YT25_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax1000_YT10_20241215150318_QMAX1000_YT10_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax500_YT15_20241215150318_QMAX500_YT15_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax500_YT30_20241215150318_QMAX500_YT30_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax1000_YT20_20241215150318_QMAX1000_YT20_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax500_YT20_20241215150318_QMAX500_YT20_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Processed file: ../../paddy_dec15_GRID_PS/PADDY_Qmax1000_YT15_20241215150318_QMAX1000_YT15_PADDYpopulation_GAUSIANscaled_summary.log, extracted 20 runs.\n",
      "Compiled and sorted data with statistics saved to 'data/GRID_PS_2.csv'.\n",
      "\n",
      "Sample of the compiled and sorted DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Run</th>\n",
       "      <th>best_MSE</th>\n",
       "      <th>Time</th>\n",
       "      <th>Avg_Best_MSE</th>\n",
       "      <th>Std_Best_MSE</th>\n",
       "      <th>Avg_Time</th>\n",
       "      <th>Std_Time</th>\n",
       "      <th>Qmax</th>\n",
       "      <th>YT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.580441</td>\n",
       "      <td>82.08</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.372298</td>\n",
       "      <td>85.91</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.793069</td>\n",
       "      <td>91.11</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.893977</td>\n",
       "      <td>95.07</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.165112</td>\n",
       "      <td>97.36</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  Run  best_MSE   Time  \\\n",
       "0  PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    1  2.580441  82.08   \n",
       "1  PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    2  2.372298  85.91   \n",
       "2  PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    3  2.793069  91.11   \n",
       "3  PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    4  1.893977  95.07   \n",
       "4  PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    5  2.165112  97.36   \n",
       "\n",
       "   Avg_Best_MSE  Std_Best_MSE  Avg_Time  Std_Time  Qmax  YT  \n",
       "0      2.181749      0.421389     93.14      7.77   500  10  \n",
       "1      2.181749      0.421389     93.14      7.77   500  10  \n",
       "2      2.181749      0.421389     93.14      7.77   500  10  \n",
       "3      2.181749      0.421389     93.14      7.77   500  10  \n",
       "4      2.181749      0.421389     93.14      7.77   500  10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_log_file(filepath):\n",
    "    \"\"\"\n",
    "    Parses a single log file to extract Run, Best MSE, and Elapsed time.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): Path to the log file.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with keys: filename, Run, best_MSE, Time\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"Run\\s+(?P<run>\\d+):\\s+Best MSE:\\s+(?P<mse>[\\d.]+),\\s+Elapsed time:\\s+(?P<time>[\\d.]+)\\s+seconds\"\n",
    "    )\n",
    "    data = []\n",
    "    filename = os.path.basename(filepath)\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            match = pattern.search(line)\n",
    "            if match:\n",
    "                run = int(match.group('run'))\n",
    "                mse = float(match.group('mse'))\n",
    "                time = float(match.group('time'))\n",
    "                data.append({\n",
    "                    'filename': filename,\n",
    "                    'Run': run,\n",
    "                    'best_MSE': mse,\n",
    "                    'Time': time\n",
    "                })\n",
    "    return data\n",
    "\n",
    "def Qmax_YT_extract(filename):\n",
    "    \"\"\"\n",
    "    Extracts Qmax and YT values from the filename.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing Qmax (int) and YT (int). Returns (None, None) if extraction fails.\n",
    "    \"\"\"\n",
    "    # Example filename:\n",
    "    # PADDY_Qmax20_YT10_20241213150301_QMAX20_YT10_PADDYgenerational_GAUSIANscaled_summary.log\n",
    "    # We need to extract Qmax20_YT10 from the first part after 'PADDY_'\n",
    "\n",
    "    pattern = re.compile(r\"PADDY_Qmax(?P<Qmax>\\d+)_YT(?P<YT>\\d+)_\")\n",
    "    match = pattern.search(filename)\n",
    "    if match:\n",
    "        Qmax = int(match.group('Qmax'))\n",
    "        YT = int(match.group('YT'))\n",
    "        return Qmax, YT\n",
    "    else:\n",
    "        # If pattern not found, return None\n",
    "        return None, None\n",
    "\n",
    "def process_logs(input_dir, output_dir, output_filename='compiled_results.csv'):\n",
    "    \"\"\"\n",
    "    Processes all .summary.log files in the input directory, computes statistics,\n",
    "    extracts Qmax and YT, sorts the DataFrame, and saves the compiled data.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Directory to search for .summary.log files.\n",
    "        output_dir (str): Directory to save the compiled CSV.\n",
    "        output_filename (str): Name of the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Compiled dataframe containing all extracted data and statistics.\n",
    "    \"\"\"\n",
    "    # Ensure input_dir exists\n",
    "    if not os.path.isdir(input_dir):\n",
    "        raise NotADirectoryError(f\"Input directory '{input_dir}' does not exist.\")\n",
    "\n",
    "    # Create output_dir if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Search for files ending with 'summary.log'\n",
    "    search_pattern = os.path.join(input_dir, '*summary.log')\n",
    "    log_files = glob.glob(search_pattern)\n",
    "\n",
    "    if not log_files:\n",
    "        print(f\"No files ending with 'summary.log' found in '{input_dir}'.\")\n",
    "        return pd.DataFrame(columns=[\n",
    "            'filename', 'Run', 'best_MSE', 'Time',\n",
    "            'Avg_Best_MSE', 'Std_Best_MSE', 'Avg_Time', 'Std_Time',\n",
    "            'Qmax', 'YT'\n",
    "        ])\n",
    "\n",
    "    all_data = []\n",
    "    for log_file in log_files:\n",
    "        file_data = parse_log_file(log_file)\n",
    "        all_data.extend(file_data)\n",
    "        print(f\"Processed file: {log_file}, extracted {len(file_data)} runs.\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        'filename', 'Run', 'best_MSE', 'Time'\n",
    "    ])\n",
    "\n",
    "    # Compute statistics for each filename\n",
    "    stats_df = df.groupby('filename').agg(\n",
    "        Avg_Best_MSE=pd.NamedAgg(column='best_MSE', aggfunc='mean'),\n",
    "        Std_Best_MSE=pd.NamedAgg(column='best_MSE', aggfunc='std'),\n",
    "        Avg_Time=pd.NamedAgg(column='Time', aggfunc='mean'),\n",
    "        Std_Time=pd.NamedAgg(column='Time', aggfunc='std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merge statistics back into the main DataFrame\n",
    "    df = pd.merge(df, stats_df, on='filename', how='left')\n",
    "\n",
    "    # Optionally, round the statistical columns for better readability\n",
    "    df['Avg_Best_MSE'] = df['Avg_Best_MSE'].round(6)\n",
    "    df['Std_Best_MSE'] = df['Std_Best_MSE'].round(6)\n",
    "    df['Avg_Time'] = df['Avg_Time'].round(2)\n",
    "    df['Std_Time'] = df['Std_Time'].round(2)\n",
    "\n",
    "    # Extract Qmax and YT from filename\n",
    "    df[['Qmax', 'YT']] = df['filename'].apply(\n",
    "        lambda x: pd.Series(Qmax_YT_extract(x))\n",
    "    )\n",
    "\n",
    "    # Sort the DataFrame by Qmax, YT, Run in ascending order\n",
    "    df_sorted = df.sort_values(by=['Qmax', 'YT', 'Run'], ascending=[True, True, True])\n",
    "\n",
    "    # Reset index after sorting\n",
    "    df_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    df_sorted.to_csv(output_path, index=False)\n",
    "    print(f\"Compiled and sorted data with statistics saved to '{output_path}'.\")\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "# ----------------------------\n",
    "# Usage Example in Jupyter Notebook\n",
    "# ----------------------------\n",
    "\n",
    "# Define the input and output directories\n",
    "input_dir = '../../paddy_dec15_GRID_PS/'    # Replace with your input directory path\n",
    "output_dir = 'data/'  # Replace with your output directory path\n",
    "output_filename = 'GRID_PS_2.csv'  # Optional: Change the output filename if desired\n",
    "\n",
    "# Process the log files and compile the results\n",
    "try:\n",
    "    compiled_df = process_logs(input_dir, output_dir, output_filename)\n",
    "    print(\"\\nSample of the compiled and sorted DataFrame:\")\n",
    "    display(compiled_df.head())  # Display first few rows using Jupyter's display\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Run</th>\n",
       "      <th>best_MSE</th>\n",
       "      <th>Time</th>\n",
       "      <th>Avg_Best_MSE</th>\n",
       "      <th>Std_Best_MSE</th>\n",
       "      <th>Avg_Time</th>\n",
       "      <th>Std_Time</th>\n",
       "      <th>Qmax</th>\n",
       "      <th>YT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.580441</td>\n",
       "      <td>82.08</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.372298</td>\n",
       "      <td>85.91</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.793069</td>\n",
       "      <td>91.11</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.893977</td>\n",
       "      <td>95.07</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.165112</td>\n",
       "      <td>97.36</td>\n",
       "      <td>2.181749</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>93.14</td>\n",
       "      <td>7.77</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...</td>\n",
       "      <td>16</td>\n",
       "      <td>1.545759</td>\n",
       "      <td>195.54</td>\n",
       "      <td>1.454002</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>186.37</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.417193</td>\n",
       "      <td>181.18</td>\n",
       "      <td>1.454002</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>186.37</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...</td>\n",
       "      <td>18</td>\n",
       "      <td>2.158709</td>\n",
       "      <td>176.05</td>\n",
       "      <td>1.454002</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>186.37</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.066826</td>\n",
       "      <td>210.14</td>\n",
       "      <td>1.454002</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>186.37</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.349620</td>\n",
       "      <td>216.87</td>\n",
       "      <td>1.454002</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>186.37</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  Run  best_MSE    Time  \\\n",
       "0    PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    1  2.580441   82.08   \n",
       "1    PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    2  2.372298   85.91   \n",
       "2    PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    3  2.793069   91.11   \n",
       "3    PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    4  1.893977   95.07   \n",
       "4    PADDY_Qmax500_YT10_20241215150318_QMAX500_YT10...    5  2.165112   97.36   \n",
       "..                                                 ...  ...       ...     ...   \n",
       "195  PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...   16  1.545759  195.54   \n",
       "196  PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...   17  1.417193  181.18   \n",
       "197  PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...   18  2.158709  176.05   \n",
       "198  PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...   19  1.066826  210.14   \n",
       "199  PADDY_Qmax1000_YT30_20241215150318_QMAX1000_YT...   20  1.349620  216.87   \n",
       "\n",
       "     Avg_Best_MSE  Std_Best_MSE  Avg_Time  Std_Time  Qmax  YT  \n",
       "0        2.181749      0.421389     93.14      7.77   500  10  \n",
       "1        2.181749      0.421389     93.14      7.77   500  10  \n",
       "2        2.181749      0.421389     93.14      7.77   500  10  \n",
       "3        2.181749      0.421389     93.14      7.77   500  10  \n",
       "4        2.181749      0.421389     93.14      7.77   500  10  \n",
       "..            ...           ...       ...       ...   ...  ..  \n",
       "195      1.454002      0.293602    186.37     17.41  1000  30  \n",
       "196      1.454002      0.293602    186.37     17.41  1000  30  \n",
       "197      1.454002      0.293602    186.37     17.41  1000  30  \n",
       "198      1.454002      0.293602    186.37     17.41  1000  30  \n",
       "199      1.454002      0.293602    186.37     17.41  1000  30  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
